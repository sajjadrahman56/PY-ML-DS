# -*- coding: utf-8 -*-
"""v_01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DANh-_yLpZEtMRgD-Yv2f8kQd-6CZymK
"""

from google.colab import drive
import os
import zipfile

# Mount Google Drive
# drive.mount('/content/gdrive')

# !pip install gdown

# import gdown

# url = 'https://drive.google.com/uc?id=1LsQTFXGqsdAmZUoRedOT_Wc3mVBVS9Al'
# output = 'data11.zip'
# gdown.download(url, output, quiet=False) # quiet=False means that you want to see the progress of the download.

import zipfile

# zip_dir = '/content/data11.zip'
# extract_dir = '/content/data'

# with zipfile.ZipFile(zip_dir, 'r') as zip_ref:
#     zip_ref.extractall(extract_dir)

import os

rootDir = '/content/data'
i=0
for dirName, subdirList, fileList in os.walk(rootDir):
    print(f'Found directory:  {dirName} and fileList ={len(fileList)} also the subDir = {subdirList}')
    for fname in fileList:
        #print('\t%s' % os.path.join(dirName, fname))
        print(fname)
        i+=1
        if(i>6):
          break







import os
import json
import torch
from PIL import Image
from torch.utils.data import Dataset, random_split, DataLoader
from torchvision import transforms

# Load the metadata
with open('/content/data/metadata.jsonl', 'r') as file:
    metadata = [json.loads(line) for line in file]

# Convert to a list of tuples (image path, label)
data = [(item['file_name'], item['text_prompt']) for item in metadata]

# Define a custom dataset
class CustomDataset(Dataset):
    def __init__(self, data, transform=None):
        self.data = data
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        image = Image.open(img_path)
        if self.transform:
            image = self.transform(image)
        return image, label

# Define a transform to convert the data into PyTorch tensors
transform = transforms.Compose([transforms.ToTensor()])

# Create the custom dataset
dataset = CustomDataset(data, transform=transform)

# Determine the lengths of your splits (e.g., 70% train, 15% valid, 15% test)
# Determine the lengths of your splits (e.g., 70% train, 15% valid, 15% test)
total = len(dataset)
train_len = int(total * 0.7)
valid_len = int(total * 0.15)
test_len = total - train_len - valid_len

lengths = [train_len, valid_len, test_len]


# Split the dataset
train_dataset, valid_dataset, test_dataset = random_split(dataset, lengths)
print(f' train_dataset = {len(train_dataset)} and test_dataset = {len(test_dataset)} and valid_set = {len(valid_dataset)}')
# Create data loaders for each split
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=128)
test_loader = DataLoader(test_dataset, batch_size=128)

print(data)

# Print the number of batches in each DataLoader
print(f"Number of batches in train_loader: {len(train_loader)}")
print(f"Number of batches in valid_loader: {len(valid_loader)}")
print(f"Number of batches in test_loader: {len(test_loader)}")

# Print the first 5 items
for i in range(10,20):
    print(data[i])



import cv2
from matplotlib import pyplot as plt

# Load the image
img = cv2.imread('/content/data/train/sample_12196.png')

# Convert the image from BGR to RGB
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image
plt.imshow(img_rgb)
plt.show()

import cv2
from matplotlib import pyplot as plt

# List of file names
file_names = [data[i][0] for i in range(10,20)]

# Loop over the file names
for file_name in file_names:
  #print(file_name)
    # Load the image
    img = cv2.imread('/content/data/'+file_name)

    # Convert the image from BGR to RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Display the image
    plt.imshow(img_rgb)
    plt.title(file_name)
    plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Function to visualize images
# Function to visualize images
def visualize_data(loader, title):
    dataiter = iter(loader)
    images, labels = dataiter.next()
    images = images.numpy()

    fig = plt.figure(figsize=(25, 4))

    for idx in np.arange(20):
        ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
        plt.imshow(images[idx].squeeze(), cmap='gray')  # Use cmap='gray' for grayscale images
        ax.set_title(str(labels[idx]))

    plt.suptitle(title)
    plt.show()


# Visualize the images and labels in each batch
visualize_data(train_loader, "Train Batch")
visualize_data(valid_loader, "Valid Batch")
visualize_data(test_loader, "Test Batch")

for i, (images, labels) in enumerate(train_loader):
    # Now images and labels contain the data from the i-th batch
    # You can add your processing code here
    print(f"Processing batch {i}")



"""# i mages looad from the train valid and test"""

import os
import json
import torch
from PIL import Image
from torch.utils.data import Dataset, random_split, DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt
import numpy as np

# Load the metadata
with open('/content/data/metadata.jsonl', 'r') as file:
    metadata = [json.loads(line) for line in file]

# Convert to a list of tuples (image path, label)
data = [(item['file_name'], item['text_prompt']) for item in metadata]

# Define a custom dataset
class CustomDataset(Dataset):
    def __init__(self, data, transform=None):
        self.data = data
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        #print(f'image paht = {img_path}')
        image = Image.open('/content/data/'+img_path)
        if self.transform:
            image = self.transform(image)
        return image, label

# Define a transform to convert the data into PyTorch tensors
transform = transforms.Compose([transforms.ToTensor()])

# Create the custom dataset
dataset = CustomDataset(data, transform=transform)

# Determine the lengths of your splits (e.g., 70% train, 15% valid, 15% test)
total = len(dataset)
train_len = int(total * 0.7)
valid_len = int(total * 0.15)
test_len = total - train_len - valid_len

# Split the dataset
train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_len, valid_len, test_len])

# Create data loaders for each split
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
valid_loader = DataLoader(valid_dataset, batch_size=128)
test_loader = DataLoader(test_dataset, batch_size=128)

# Function to visualize images
# Function to visualize images
# Function to visualize images
def visualize_data(loader, title):
    for images, labels in loader:
        # Now images and labels contain the data from the first batch
        break
    images = images.numpy()

    fig = plt.figure(figsize=(25, 4))

    for idx in np.arange(20):
        ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])  # Use int() to convert float to integer
        plt.imshow(images[idx].squeeze(), cmap='gray')  # Use cmap='gray' for grayscale images
        ax.set_title(str(labels[idx]))

    plt.suptitle(title)
    plt.show()

# Visualize the images and labels in each batch
visualize_data(train_loader, "Train Batch")
visualize_data(valid_loader, "Valid Batch")
visualize_data(test_loader, "Test Batch")













