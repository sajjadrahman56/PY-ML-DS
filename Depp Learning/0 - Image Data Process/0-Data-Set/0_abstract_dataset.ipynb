{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WVTJXFVvXK9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1LsQTFXGqsdAmZUoRedOT_Wc3mVBVS9Al'\n",
        "output = 'data11.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "-lUhEd-SZggp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_dir = '/content/data11.zip'\n",
        "extract_dir = '/content/data'\n",
        "\n",
        "with zipfile.ZipFile(zip_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "Uh0pohtTZ1_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "CMhSCZWTl74w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the data path and its sub directories\n",
        "rootDir = '/content/data'\n",
        "i=0\n",
        "for dirName, subdirList, fileList in os.walk(rootDir):\n",
        "    print(f'Found directory:  {dirName} and fileList ={len(fileList)} also the and subDir = {subdirList} subDir len  = {len(subdirList)}')\n",
        "    for fname in fileList:\n",
        "        #print('\\t%s' % os.path.join(dirName, fname))\n",
        "        print(fname)\n",
        "        i+=1\n",
        "        if(i>8):\n",
        "          break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swihAhbVZ25M",
        "outputId": "c20cf456-61b6-48f0-a008-953a906bd817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found directory:  /content/data and fileList =1 also the and subDir = ['train'] subDir len  = 1\n",
            "metadata.jsonl\n",
            "Found directory:  /content/data/train and fileList =99999 also the and subDir = [] subDir len  = 0\n",
            "sample_55665.png\n",
            "sample_40738.png\n",
            "sample_96797.png\n",
            "sample_45094.png\n",
            "sample_87703.png\n",
            "sample_62042.png\n",
            "sample_94527.png\n",
            "sample_29311.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the metadata\n",
        "with open('/content/data/metadata.jsonl', 'r') as file:\n",
        "    metadata = [json.loads(line) for line in file]\n",
        "\n",
        "# Organize the data by label\n",
        "data_by_label = defaultdict(list)\n",
        "for item in metadata:\n",
        "    data_by_label[item['text_prompt']].append(item)\n",
        "\n",
        "# Determine the number of samples per class\n",
        "samples_per_class = 2000 // len(data_by_label)\n",
        "\n",
        "# Create a new directory for the smaller dataset\n",
        "os.makedirs('/content/smaller_dataset299/train', exist_ok=True)\n",
        "\n",
        "# Copy the images to the new directory and collect new metadata\n",
        "new_metadata = []\n",
        "for label, items in data_by_label.items():\n",
        "    for item in items[:samples_per_class]:\n",
        "        old_path = '/content/data/' + item['file_name']\n",
        "        new_path = '/content/smaller_dataset299/' + item['file_name']\n",
        "        shutil.copy(old_path, new_path)\n",
        "        item['file_name'] = new_path  # Update file path in the metadata\n",
        "        new_metadata.append(item)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nE7eSk-TlmwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new metadata file for the smaller dataset\n",
        "with open('/content/smaller_dataset299/smaller_metadata.jsonl', 'w') as file:\n",
        "    for item in new_metadata:\n",
        "        file.write(json.dumps(item) + '\\n')"
      ],
      "metadata": {
        "id": "UGTsbcVRnqyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rootDir = '/content/smaller_dataset299'\n",
        "i=0\n",
        "for dirName, subdirList, fileList in os.walk(rootDir):\n",
        "    print(f'Found directory:  {dirName} and fileList ={len(fileList)} also the and subDir = {subdirList} subDir len  = {len(subdirList)}')\n",
        "    for fname in fileList:\n",
        "        #print('\\t%s' % os.path.join(dirName, fname))\n",
        "        print(fname)\n",
        "        i+=1\n",
        "        if(i>8):\n",
        "          break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcPuNYbLrHPt",
        "outputId": "1644b8c9-5c0b-4192-a4a1-0d4dbcbf64bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found directory:  /content/smaller_dataset299 and fileList =1 also the and subDir = ['train'] subDir len  = 1\n",
            "smaller_metadata.jsonl\n",
            "Found directory:  /content/smaller_dataset299/train and fileList =1998 also the and subDir = [] subDir len  = 0\n",
            "sample_33825.png\n",
            "sample_33578.png\n",
            "sample_66737.png\n",
            "sample_33850.png\n",
            "sample_33793.png\n",
            "sample_67120.png\n",
            "sample_66791.png\n",
            "sample_398.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the metadata\n",
        "metadata = []\n",
        "with open('/content/smaller_dataset299/smaller_metadata.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        metadata.append(json.loads(line))\n",
        "\n",
        "# Count the number of each masking level\n",
        "masking_counts = {'Low masking level': 0, 'Medium masking level': 0, 'High masking level': 0}\n",
        "for data in metadata:\n",
        "  # print(data)\n",
        "    masking_counts[data['text_prompt']] += 1\n",
        "\n",
        "# Plot the counts\n",
        "# plt.bar(masking_counts.keys(), masking_counts.values())\n",
        "# plt.title('Masking Level Counts')\n",
        "# plt.xlabel('Masking Level')\n",
        "# plt.ylabel('Count')\n",
        "# plt.show()\n",
        "print(masking_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBYJKh4vrHMw",
        "outputId": "9e1e6758-7a0e-46ae-b294-b97a700dd60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Low masking level': 666, 'Medium masking level': 666, 'High masking level': 666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Create a zip file for the folder\n",
        "shutil.make_archive('/content/smaller_dataset299', 'zip', '/content/smaller_dataset299')\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content/smaller_dataset299.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "hx0rUcrurHKZ",
        "outputId": "aaf4d77d-82d7-4216-ea27-54804115d042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3c9302c7-70e8-4b5f-9e72-1439332e6d3b\", \"smaller_dataset299.zip\", 199440516)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PriTX-torHHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}